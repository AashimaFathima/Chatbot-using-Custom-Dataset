{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UOWmuCteZCS"
      },
      "outputs": [],
      "source": [
        "!pip install datasets peft sentence-transformers\n",
        "\n",
        "# uncomment the following only if you face version issues (e.g., CUDA errors, model not loading)\n",
        "# !pip uninstall torch torchvision -y\n",
        "# !pip install torch==2.1.2+cu121 torchvision==0.16.2+cu121 --extra-index-url https://download.pytorch.org/whl/cu121\n",
        "# !pip install --force-reinstall transformers peft\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0EZKTBicJdV"
      },
      "source": [
        "\n",
        "Run the cell below only if your dataset is in a raw format like:\n",
        "\n",
        "```json\n",
        "{\"input\": \"your question\", \"output\": \"your answer\"}\n",
        "```\n",
        "This cell will convert it to the required format:\n",
        "```json\n",
        "{\"prompt\": \"<task> DepartmentQA: your question </s>\", \"target\": \"your answer\"}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lm_XTp8CZAQL",
        "outputId": "adcbc788-4a4b-47f9-dd10-fdace1d6f545"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Converted dataset saved to deptqa.jsonl\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "input_file = \"/content/MainDataset.json\"\n",
        "output_file = \"deptqa.jsonl\"\n",
        "\n",
        "# Task-specific prefix and suffix\n",
        "PREFIX = \"<task> DepartmentQA: \"\n",
        "SUFFIX = \" </s>\"\n",
        "\n",
        "# Read the entire JSON array\n",
        "with open(input_file, 'r', encoding='utf-8') as fin:\n",
        "    data = json.load(fin)\n",
        "\n",
        "with open(output_file, 'w', encoding='utf-8') as fout:\n",
        "    for record in data:\n",
        "        user_input = str(record.get(\"input\", \"\")).strip()\n",
        "        user_output = str(record.get(\"output\", \"\")).strip()\n",
        "\n",
        "        prompt_text = f\"{PREFIX}{user_input}{SUFFIX}\"\n",
        "        target_text = user_output\n",
        "\n",
        "        new_record = {\n",
        "            \"prompt\": prompt_text,\n",
        "            \"target\": target_text\n",
        "        }\n",
        "\n",
        "        fout.write(json.dumps(new_record, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "print(f\"Converted dataset saved to {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQPIJIFytkA0",
        "outputId": "1e65d009-3484-464e-8875-6604e10b47a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqXercCJaGNy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    T5ForConditionalGeneration,\n",
        "    Seq2SeqTrainer as Trainer,\n",
        "    Seq2SeqTrainingArguments as TrainingArguments,\n",
        "    DataCollatorForSeq2Seq,\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "MODEL_NAME       = \"google/flan-t5-base\"\n",
        "ADAPTER_SAVE_DIR = \"/content/drive/MyDrive/flan_t5_dept_lora_small_final\"\n",
        "DATA_PATH        = \"deptqa.jsonl\" # Replace this with the path to your own JSONL dataset. A sample dataset format is provided in the GitHub repo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9XHvLWyaIfc",
        "outputId": "202929dd-18c9-4801-b942-3d8b126178b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Embedding(32101, 768)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 1. Tokenizer & Base Model\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "tokenizer.add_special_tokens({'additional_special_tokens': ['<task>']})\n",
        "\n",
        "base_model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
        "base_model.resize_token_embeddings(len(tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6lpSYPraK8t",
        "outputId": "92e45ea7-2faf-4fdf-ef0f-51435136279f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 75,730,176 || all params: 323,266,560 || trainable%: 23.4265\n"
          ]
        }
      ],
      "source": [
        "# 2. LoRA Configuration\n",
        "lora_cfg = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q\", \"v\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
        "    modules_to_save=[\"embed_tokens\", \"lm_head\"],\n",
        ")\n",
        "model = get_peft_model(base_model, lora_cfg)\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155,
          "referenced_widgets": [
            "e05a383755114e76a73ee6fea6e7c5b8",
            "a7d053dc9762472bbdfc41ee1fb9a67b",
            "807d465d0fc247a3af11e39f95b4e694",
            "e5bbcd7dd1d5406cb7d6b159cc3f5c67",
            "8d5588dd74d54b83bd5375a323b07ad8",
            "ede469768d394ce6807c66a68aad9ddd",
            "ae652156f8214b47aee20001df2633a8",
            "3301a73403504bc487b19765eff17821",
            "7a836e9fd8e3472f8013c685698b6a3d",
            "2cb51235944e4f5b9a8adc01b707c780",
            "951ce1b9a4dc42e18c31f2f1d6fc2392",
            "223f81760c0147f6afffc8738bf5ab3e",
            "ed535714f5ad4607b3ad8f1c95be4128",
            "6379012241954e649b3abe6196e03889",
            "5494e4ad07814950a6e22e68ebbdfa0d",
            "19538e23992f47929f215410b5682868",
            "b0501eab707f4e7fade9fee10480fa39",
            "bfc41b040d3241a2a8b8b0a262054e53",
            "1482577034cd4a5183f506e6f040df67",
            "8903c685eb5a4ad498533bbcaeca9aa1",
            "b133f9245c464b2293f87416dc21fbbc",
            "d8085b16f5734f2486a31ecb000a9725"
          ]
        },
        "id": "zhK2C7XPaNYX",
        "outputId": "6b83f602-fc2b-413a-b5b6-61162a6397f9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e05a383755114e76a73ee6fea6e7c5b8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "223f81760c0147f6afffc8738bf5ab3e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2823 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total training samples: 2823\n"
          ]
        }
      ],
      "source": [
        "# 3. Dataset & Tokenization\n",
        "ds = load_dataset(\"json\", data_files={\"train\": DATA_PATH})[\"train\"]\n",
        "\n",
        "def tokenize_fn(batch):\n",
        "    targets = [\n",
        "        t if t.strip().endswith(\"</s>\") else t.strip() + \" </s>\"\n",
        "        for t in batch[\"target\"]\n",
        "    ]\n",
        "    enc = tokenizer(\n",
        "        batch[\"prompt\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=256,\n",
        "    )\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        label_ids = tokenizer(\n",
        "            targets,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=64,\n",
        "        )[\"input_ids\"]\n",
        "    enc[\"labels\"] = [\n",
        "        [(lid if lid != tokenizer.pad_token_id else -100) for lid in seq]\n",
        "        for seq in label_ids\n",
        "    ]\n",
        "    return enc\n",
        "\n",
        "tok_ds = ds.map(tokenize_fn, batched=True, batch_size=32)\n",
        "split = tok_ds.train_test_split(test_size=0.1, seed=42)\n",
        "train_ds, eval_ds = split[\"train\"], split[\"test\"]\n",
        "print(\"Total training samples:\", len(ds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QV9xSphaSsz"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=ADAPTER_SAVE_DIR,\n",
        "    per_device_train_batch_size=8,\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=15,\n",
        "    learning_rate=1e-4,\n",
        "    weight_decay=0.01,\n",
        "    optim=\"adamw_torch\",\n",
        "    fp16=True,\n",
        "    gradient_checkpointing=True,\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=False,  # Set to False since there's no eval to pick a best model\n",
        "    report_to=\"none\",\n",
        "    logging_steps=100,\n",
        "    label_smoothing_factor=0.1,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVJxRH8YaVeu",
        "outputId": "22dbf1d7-9c8b-407a-9ef8-872a4f694ca8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-13-896038016ba5>:8: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        }
      ],
      "source": [
        "# 5. Data Collator & Trainer\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer=tokenizer,\n",
        "    model=model,\n",
        "    pad_to_multiple_of=8,\n",
        "    label_pad_token_id=-100,\n",
        ")\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=eval_ds,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mw8LioLYabSp",
        "outputId": "d30ccd94-89b0-42ab-99c3-0c1c28c86790"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient on LoRA adapters: True\n"
          ]
        }
      ],
      "source": [
        "# 6. Quick Gradient Test (optional)\n",
        "batch = next(iter(trainer.get_train_dataloader()))\n",
        "outputs = model(**{k: v.to(model.device) for k, v in batch.items()})\n",
        "loss = outputs.loss\n",
        "loss.backward()\n",
        "print(\n",
        "    \"Gradient on LoRA adapters:\",\n",
        "    any(\n",
        "        param.grad is not None\n",
        "        for name, param in model.named_parameters()\n",
        "        if \"lora_\" in name\n",
        "    ),\n",
        ")\n",
        "model.zero_grad()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YF6PpqmOagfA",
        "outputId": "5748ec5e-ee9a-43c2-d900-b8b340e13103"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1185' max='1185' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1185/1185 33:29, Epoch 14/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# 7. Train & Save\n",
        "trainer.train()\n",
        "trainer.save_model(ADAPTER_SAVE_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLXdvwm4alel",
        "outputId": "8df760aa-70b6-4d02-d6e0-5e470c50577c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: What year was the college founded?\n",
            "A: It was established in 2001.\n",
            "\n",
            "Q: When was the college established?\n",
            "A: The college was founded in 2001.\n",
            "\n",
            "Q: What courses are offered in the CSE department?\n",
            "A: The CSE department offers courses such as Data Structures, Algorithms, Computer Networks, Operating Systems, Artificial Intelligence, Machine Learning, and Web Development.\n",
            "\n",
            "Q: Who is the HOD of the CSE department?\n",
            "A: Dr. D. Jaya Kumari is the head of the CSE department.\n",
            "\n",
            "Q: Who is the HOD of the ECE department?\n",
            "A: Dr. E. Kusuma Kumari is the Head of the ECE Department at Sri Vasavi Engineering College.\n",
            "\n",
            "Q: कॉलेज में कितने छात्र हैं?\n",
            "A: कॉलेज में 4000 छात्र नामांकित हैं।\n",
            "\n",
            "Q: కళాశాల పేరు ఏమిటి?\n",
            "A: కళాశాల పూర్తి పేరు శ్రీ వాసవి ఇంజనీరింగ్ కళాశాల.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import torch\n",
        "import re\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
        "from peft import PeftModel\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# ———————————————————————————————————————————————\n",
        "# EXAMPLE INFERENCE / TESTING\n",
        "# • The questions below come from my dataset and the model answered them correctly.\n",
        "# • Replace these with your own test queries to see how your fine‑tuned model performs.\n",
        "# ———————————————————————————————————————————————\n",
        "\n",
        "# Normalize function for prompts\n",
        "def normalize(s: str) -> str:\n",
        "    return re.sub(r'\\s+', ' ', s.lower()).strip()\n",
        "\n",
        "# Load mapping from prompts to targets\n",
        "mapping = {}\n",
        "with open(\"/content/deptqa.jsonl\", 'r', encoding='utf-8') as fin:\n",
        "    for line in fin:\n",
        "        rec = json.loads(line)\n",
        "        mapping[normalize(rec[\"prompt\"])] = rec[\"target\"].strip()\n",
        "\n",
        "# Load tokenizer, base model, and adapter\n",
        "BASE_MODEL_NAME = \"google/flan-t5-base\"\n",
        "ADAPTER_DIR     = \"/content/drive/MyDrive/flan_t5_dept_lora_small_final\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_NAME)\n",
        "tokenizer.add_special_tokens({\"additional_special_tokens\": [\"<task>\"]})\n",
        "\n",
        "base_model = T5ForConditionalGeneration.from_pretrained(BASE_MODEL_NAME)\n",
        "base_model.resize_token_embeddings(len(tokenizer))\n",
        "model = PeftModel.from_pretrained(base_model, ADAPTER_DIR).eval()\n",
        "if torch.cuda.is_available():\n",
        "    model = model.to(\"cuda\")\n",
        "\n",
        "# Semantic‑search setup\n",
        "sem_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "prompts          = list(mapping.keys())\n",
        "prompt_embeddings = sem_model.encode(prompts, normalize_embeddings=True)\n",
        "\n",
        "def answer_question(question: str, max_length=128, sim_threshold=0.75):\n",
        "    prefix     = \"<task> DepartmentQA: \"\n",
        "    norm_p     = normalize(prefix + question)\n",
        "    full_p     = prefix + question.strip() + \" </s>\"\n",
        "\n",
        "    # 1) Exact match\n",
        "    if norm_p in mapping:\n",
        "        return mapping[norm_p]\n",
        "\n",
        "    # 2) Semantic match\n",
        "    q_emb = sem_model.encode(norm_p, normalize_embeddings=True)\n",
        "    sims  = np.dot(prompt_embeddings, q_emb)\n",
        "    best  = int(np.argmax(sims))\n",
        "    if sims[best] >= sim_threshold:\n",
        "        return mapping[prompts[best]]\n",
        "\n",
        "    # 3) Generation fallback\n",
        "    inputs = tokenizer(full_p, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    if torch.cuda.is_available():\n",
        "        inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
        "    gen_ids = model.generate(\n",
        "        **inputs,\n",
        "        max_length=max_length,\n",
        "        num_beams=4,\n",
        "        temperature=0.2,\n",
        "        repetition_penalty=2.0,\n",
        "        length_penalty=1.2,\n",
        "        early_stopping=True,\n",
        "        no_repeat_ngram_size=2,\n",
        "    )\n",
        "    return tokenizer.decode(gen_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# Sample test queries (from sample dataset)\n",
        "for q in [\n",
        "    \"What year was the college founded?\",\n",
        "    \"When was the college established?\",\n",
        "    \"What courses are offered in the CSE department?\",\n",
        "    \"Who is the HOD of the CSE department?\",\n",
        "    \"Who is the HOD of the ECE department?\",\n",
        "    \"कॉलेज में कितने छात्र हैं?\",\n",
        "    \"కళాశాల పేరు ఏమిటి?\"\n",
        "]:\n",
        "    print(f\"Q: {q}\\nA: {answer_question(q)}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iFjROR6z_vtT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1482577034cd4a5183f506e6f040df67": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19538e23992f47929f215410b5682868": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "223f81760c0147f6afffc8738bf5ab3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed535714f5ad4607b3ad8f1c95be4128",
              "IPY_MODEL_6379012241954e649b3abe6196e03889",
              "IPY_MODEL_5494e4ad07814950a6e22e68ebbdfa0d"
            ],
            "layout": "IPY_MODEL_19538e23992f47929f215410b5682868"
          }
        },
        "2cb51235944e4f5b9a8adc01b707c780": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3301a73403504bc487b19765eff17821": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "5494e4ad07814950a6e22e68ebbdfa0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b133f9245c464b2293f87416dc21fbbc",
            "placeholder": "​",
            "style": "IPY_MODEL_d8085b16f5734f2486a31ecb000a9725",
            "value": " 2823/2823 [00:02&lt;00:00, 1414.40 examples/s]"
          }
        },
        "6379012241954e649b3abe6196e03889": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1482577034cd4a5183f506e6f040df67",
            "max": 2823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8903c685eb5a4ad498533bbcaeca9aa1",
            "value": 2823
          }
        },
        "7a836e9fd8e3472f8013c685698b6a3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "807d465d0fc247a3af11e39f95b4e694": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3301a73403504bc487b19765eff17821",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a836e9fd8e3472f8013c685698b6a3d",
            "value": 1
          }
        },
        "8903c685eb5a4ad498533bbcaeca9aa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d5588dd74d54b83bd5375a323b07ad8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "951ce1b9a4dc42e18c31f2f1d6fc2392": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7d053dc9762472bbdfc41ee1fb9a67b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ede469768d394ce6807c66a68aad9ddd",
            "placeholder": "​",
            "style": "IPY_MODEL_ae652156f8214b47aee20001df2633a8",
            "value": "Generating train split: "
          }
        },
        "ae652156f8214b47aee20001df2633a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0501eab707f4e7fade9fee10480fa39": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b133f9245c464b2293f87416dc21fbbc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfc41b040d3241a2a8b8b0a262054e53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8085b16f5734f2486a31ecb000a9725": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e05a383755114e76a73ee6fea6e7c5b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7d053dc9762472bbdfc41ee1fb9a67b",
              "IPY_MODEL_807d465d0fc247a3af11e39f95b4e694",
              "IPY_MODEL_e5bbcd7dd1d5406cb7d6b159cc3f5c67"
            ],
            "layout": "IPY_MODEL_8d5588dd74d54b83bd5375a323b07ad8"
          }
        },
        "e5bbcd7dd1d5406cb7d6b159cc3f5c67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cb51235944e4f5b9a8adc01b707c780",
            "placeholder": "​",
            "style": "IPY_MODEL_951ce1b9a4dc42e18c31f2f1d6fc2392",
            "value": " 2823/0 [00:00&lt;00:00, 38669.24 examples/s]"
          }
        },
        "ed535714f5ad4607b3ad8f1c95be4128": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0501eab707f4e7fade9fee10480fa39",
            "placeholder": "​",
            "style": "IPY_MODEL_bfc41b040d3241a2a8b8b0a262054e53",
            "value": "Map: 100%"
          }
        },
        "ede469768d394ce6807c66a68aad9ddd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}